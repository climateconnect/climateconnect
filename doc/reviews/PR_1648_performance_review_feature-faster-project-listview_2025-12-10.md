### Performance Review — Python Backend (branch: `feature/faster-project-listview`)

#### Author/date
- Generated by automated reviewer on 2025-12-10 17:30 local time

#### Scope
- Reviewed backend changes on current branch vs `origin/master` with focus on performance characteristics, risks, and improvements.
- Changed backend files detected:
  - `backend/climateconnect_api/utility/badges.py`
  - `backend/organization/serializers/project.py`
  - `backend/organization/utility/project_ranking.py`
  - `backend/organization/views/project_views.py`

No code has been altered in this report; all items below are recommendations.

---

### Summary of Findings
- Positive: Reduced N+1s via `select_related`/`prefetch_related` and serializer support for annotated counts are good steps for the projects list view.
- Risk: Prefetching deep relations (donations, badges) for every project in lists can grow superlinearly; apply field limiting and conditional prefetching.
- Risk: Ranking randomization on every request harms cache hit rates and leads to unstable ordering; consider deterministic per-window randomization and aggressive caching.
- Issue: A queryset assigned to `self._cached_queryset` in `ListProjectsView.get_queryset` is not consumed anywhere; no actual caching effect.
- DB/Query: Broad `.annotate(Count(..., distinct=True))` over joins can be costly; subqueries or pre-aggregated counters may be preferable at scale.
- Caching: Badge catalogue caching via `@lru_cache` is per-process with time-based invalidation; better to use central Django cache and explicit invalidation on writes.
- Indexing: Filters used in the list view imply several composite indexes that should be verified.

---

### Detailed Analysis and Recommendations

#### 1) `backend/organization/views/project_views.py`
Key changes observed:
- Import of `Count` and use of `.annotate(comment_count=Count("project_comment", distinct=True), like_count=Count("project_liked", distinct=True))` for the list view.
- Heavier prefetch plan including:
  - `select_related("loc", "language", "status")` — good
  - `prefetch_related("tag_project")` (TODO to remove), `project_parent` with nested prefetches of donations and user badges, and `project_sector_mapping` with `select_related("sector")`.
- Ranking order applied via a `Case/When` over `ranked_project_ids`.
- A local assignment `self._cached_queryset = queryset` that is not read elsewhere.

Findings and suggestions:
- Annotations cost
  - Using `Count(..., distinct=True)` over joins can produce expensive GROUP BY queries once combined with multiple prefetches.
  - Consider replacing with Subquery annotations that use separate aggregations against `ProjectComment` and `ProjectLike` tables to avoid DISTINCT over large join products. Example pattern (conceptual):
    - `comment_count=Subquery(ProjectComment.objects.filter(project=OuterRef("pk")).order_by().values("project").annotate(c=Count("id")).values("c")[:1])`.
  - Alternatively, if eventual consistency is acceptable, maintain denormalized counters on `Project` updated via signals or atomic updates.

- Prefetch plan sizing
  - `project_parent -> parent_user -> donation_user` and `userbadge_user` for every project is likely unnecessary on the list page if badges/donations are only used for detailed cards or rarely displayed metadata.
  - Recommendations:
    - Gate expensive prefetches behind an explicit query param or a context flag used only on pages that require them.
    - Narrow fields with `.only(...)` on the prefetch querysets (e.g., only `id`, `date_first_received`, `donation_amount`, and for badges only fields actually accessed). This reduces Python object instantiation and memory.
    - If only counts or the existence of a badge is needed, prefer boolean/aggregated annotations instead of pulling full rows.

- Ranking order via `Case/When`
  - For long result sets, building a large `Case/When` can increase SQL size; ensure pagination keeps lists small. If lists can exceed a few hundred items, consider writing the ranked IDs into a temp table or caching the sorted ID list and fetching with `id__in` preserving order via `FIELD`/`array_position` equivalent (DB-specific) — or use the `Case` only within a limited page slice.

- Caching
  - `self._cached_queryset` currently has no effect; it is not re-used within the view lifecycle. Consider either removing it or implementing an actual cache strategy:
    - Cache ranked project ID lists keyed by filters (hub, sectors, collaboration, location bounds, etc.), and then page by slicing the cached ID list.
    - Use `generate_project_ranking_cache_key(...)` with normalized parameters to maximize reuse. Ensure invalidation when interactions that affect ranking change (comments/likes/follows) if strong consistency is required.

- Geospatial filters
  - Where `.annotate(distance=Distance(...))` is used with `order_by("distance")`: confirm spatial indexes on `loc.centre_point` and `loc.multi_polygon` columns (GiST/BRIN depending on database). If not present, add appropriate indexes.
  - Avoid applying distance annotation unless sorting by distance or returning it; compute conditionally based on the presence of `place/osm` params.

- Distinct usage
  - Calls like `.filter(project_sector_mapping__sector_id__in=...).distinct()` can be expensive. Verify there is a unique constraint or adequate index on the mapping table to reduce duplicates; where feasible, deduplicate at the join source (e.g., using subquery that selects distinct project IDs first) to avoid DISTINCT over the full projection.

Prioritized actions:
1) Remove or repurpose `self._cached_queryset` into a real cache of ranked IDs keyed by normalized filters. Effort: M, Impact: H
2) Replace `Count(..., distinct=True)` with Subquery counts or denormalized counters. Effort: M, Impact: M–H
3) Restrict heavy prefetches (donations/badges) behind a flag or convert to aggregated annotations. Effort: M, Impact: H
4) Verify and add spatial indexes; compute distances only when required. Effort: S, Impact: M

Metrics to monitor:
- SQL time and rows for list view endpoints; ORM query counts; cache hit ratio for ranked ID lists; p95 latency for the list view.

---

#### 2) `backend/organization/serializers/project.py`
Key changes observed:
- `ProjectStubSerializer`: removed `tags` from fields (good, reduces payload); added logic to use `comment_count` and `like_count` annotations when present to avoid per-object `.count()` queries.

Findings and suggestions:
- Good practice: Keep using annotation-aware accessors to avoid N+1 counts.
- Clean-up: Consider removing the obsolete `get_tags` method once frontend migration is complete to prevent accidental prefetching via `tag_project`.
- If badges/donations data are ever serialized here, use `.only(...)` and avoid serializing large related objects on the list view.

Prioritized actions:
1) Remove `get_tags` and `tag_project` prefetch once frontend no longer requires tags. Effort: S, Impact: M
2) Keep serializer methods resilient to missing annotations (already implemented). Effort: S, Impact: S

---

#### 3) `backend/climateconnect_api/utility/badges.py`
Key changes observed:
- Introduced `@lru_cache(maxsize=1)` for active `DonorBadge` catalogue with a TTL hash based on the current minute.
- Donation and UserBadge query usage optimized to utilize prefetches if already present on `user`.

Findings and suggestions:
- The per-process `lru_cache` reduces DB hits but has caveats:
  - Cache is per Python process; under multi-worker deployments, each worker queries once per TTL window.
  - Time-based invalidation can keep stale data for up to 60s even after badge changes.
  - No explicit invalidation on badge updates.

Recommendations:
- Prefer central `django.core.cache` with a specific key (e.g., `active_donor_badges:v1`) and invalidate on `DonorBadge` save/delete signals. Keep a reasonable TTL fallback (e.g., 1h).
- Limit fields returned by the `DonorBadge` query (already done via `.only(...)`). Ensure ordering is supported by existing indexes on `regular_donor_minimum_duration`, `instantly_awarded_over_amount` (or accept sequential scan for tiny table size).
- In `__extract_donations_in_streak`, current O(N log N) sort is fine for small N; if donors can have large histories, consider bounding the examined window (e.g., last 2 years) before sorting.

Prioritized actions:
1) Replace `@lru_cache` with Django cache and add signal-based invalidation. Effort: S–M, Impact: M
2) If donation volumes per user are large, consider restricting the date range prior to sorting. Effort: S, Impact: S–M

---

#### 4) `backend/organization/utility/project_ranking.py`
Key changes observed:
- Introduced `_randomize_ranking` using `random.triangular` and applied randomization for non-past events, with intent to reshuffle ranking per page visit.
- Caching framework hooks exist (`generate_project_ranking_cache_key`, `DEFAULT_CACHE_TIMEOUT_IN_SECONDS`).

Findings and suggestions:
- Randomization vs caching:
  - Per-request randomization will destroy cache hit rates for ranked lists, causing extra CPU/DB work and unstable UX. It also complicates pagination (page drift).
  - Suggest using a deterministic salt that changes infrequently, e.g., daily seed (`date`), or a seed based on the user/session to provide variety without cache thrashing.
  - Cache the computed ranked project ID lists keyed by: filters + seed window. Keep TTL aligned with the seed window (e.g., 1 day if seeded by date).

- Database query construction:
  - Review reveals raw SQL or complex aggregations (the file includes notes about grouping). Ensure all non-aggregated selected columns are present in `GROUP BY` for DBs that enforce it, or move to subqueries/CTEs that compute aggregates per project and join back.
  - If using Django ORM, prefer `annotate(...)` and Subqueries; if raw SQL is a must, add tests to verify DB portability (PostgreSQL recommended).

- Weighting and recency
  - The recency scoring uses multiple time buckets; this is CPU-only and fine. Ensure timestamps used are already available from pre-annotations to avoid extra queries.

Prioritized actions:
1) Replace per-request randomization with deterministic per-window seed (daily or weekly) and include it in the cache key. Effort: M, Impact: H
2) Cache ranked ID lists aggressively and fetch pages by slicing the cached list. Effort: M, Impact: H
3) Audit SQL/ORM groupings; convert to ORM subqueries or add proper `GROUP BY` for portability. Effort: M, Impact: M–H

---

### Indexing Checklist (verify and add if missing)
- `organization_projectsectorMapping(sector_id, project_id)` composite index (direction per DB) to accelerate sector filtering.
- `organization_projectparents(parent_organization_id, parent_user_id, project_id)` depending on access patterns.
- `organization_project(loc_id)` and spatial indexes:
  - GiST on `location.multi_polygon`, `location.centre_point` for PostGIS.
- Interaction tables:
  - `organization_projectcomment(project_id, created_at)`
  - `organization_projectlike(project_id, created_at)`
  - `organization_projectfollower(project_id, created_at)`
- Hub relations:
  - For `related_hubs` M2M table: `(hub_id, project_id)` index.

Where counts are frequently queried, covering indexes including `(project_id)` suffice; add `(created_at)` second if ordering by recent.

---

### Caching Strategy Proposal for Project List
1) Normalize filter params (hub slug, sector ids sorted, collaboration flag, location rounding bucket, status list, skills list, organization_type list, pagination page/size, language) into a stable cache key via `generate_project_ranking_cache_key`.
2) Compute the ranked project ID list once per normalized filter + seed window; cache for the window duration.
3) Serve API pages by slicing this ID list and fetching projects with `id__in` preserving order (via `Case/When` for just the slice, not the entire set).
4) Invalidate or soft-refresh on interaction events (new comment/like/follow) if strong consistency is required; otherwise rely on short TTLs and recency weighting.
5) Use per-hub caches where applicable to increase reuse.

---

### Observability & Profiling Plan
- Add per-endpoint metrics: total time, DB time, query count, cache hit/miss, rows scanned/returned (via Django Debug Toolbar in dev and lightweight middleware in prod).
- Capture slow SQL logs (>200ms) to identify heavy join/distinct queries.
- Use sampling profilers (py-spy/pyinstrument) on the list endpoint under load to inspect Python-side overhead from serializer and queryset evaluation.
- Add unit/integration tests for ranking determinism within a seed window and pagination stability.

---

### Quick Wins (1–3 days)
- Remove redundant `self._cached_queryset` or implement real caching of ranked IDs.
- Gate heavy prefetches; add `.only(...)` to prefetch querysets.
- Verify and add missing spatial and foreign key indexes.
- Replace `Count(..., distinct=True)` with Subquery counts on large lists.
- Move `tags` field removal to completion (drop `get_tags` and the `tag_project` prefetch once FE updated).

### Medium-Term (1–2 weeks)
- Implement deterministic seeded randomization and ID-list caching strategy.
- Optionally denormalize interaction counters on `Project` with signals or background jobs.
- Introduce response caching at the API layer for anonymous traffic with Vary-by-filter headers.

### Long-Term
- Consider a materialized view or background job that periodically computes ranked project IDs per hub/segment.
- Evaluate moving ranking to a separate service if complexity grows (feature flags, A/B tests, per-user personalization).

---

### Appendix: Notable Code Locations
- Annotations and ordering in list view: `backend/organization/views/project_views.py` around lines 350–407.
- Serializer annotation-aware methods: `backend/organization/serializers/project.py` around lines 391–403.
- Badge catalogue caching: `backend/climateconnect_api/utility/badges.py` lines ~119–144.
- Ranking randomization and weights: `backend/organization/utility/project_ranking.py` lines ~18–35 and application near final score computation.

---

### Final Notes
- The changes on this branch head in the right direction (reducing N+1s and enabling annotations). Applying the recommendations above should stabilize latency, improve cache utilization, and scale the list view under higher traffic without sacrificing relevance.
